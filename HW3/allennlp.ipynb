{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.data.tokenizers import Tokenizer, WordTokenizer, CharacterTokenizer\n",
    "from allennlp.data.fields import LabelField, TextField, Field\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer, TokenCharactersIndexer\n",
    "\n",
    "from overrides import overrides\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@DatasetReader.register('tncrl')\n",
    "class TNCRLDatasetReader(DatasetReader):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 token_indexers = None, tokenizer = None, lazy = False) -> None:\n",
    "        super().__init__(lazy=lazy)\n",
    "        \n",
    "        self._tokenizer = tokenizer or CharacterTokenizer()\n",
    "        self._token_indexers = token_indexers or {'tokens': TokenCharactersIndexer()}\n",
    "        \n",
    "    @overrides\n",
    "    def text_to_instance(self, before: str, after: int, class_: str) -> Instance:\n",
    "        fields: Dict[str, Field] = dict()\n",
    "        tokens_before = self._tokenizer.tokenize(before)\n",
    "        tokens_after = self._tokenizer.tokenize(after)\n",
    "        fields['tokens_before'] = TextField(tokens_before, self._token_indexers)\n",
    "        fields['tokens_after'] = TextField(tokens_after, self._token_indexers)\n",
    "        fields['class'] = LabelField(class_)\n",
    "        return Instance(fields)\n",
    "    \n",
    "    @overrides\n",
    "    def _read(self, file_path):\n",
    "        train = pd.read_csv('data/ru_train.csv')\n",
    "        for i in range(len(train)):\n",
    "            yield self.text_to_instance(str(train.loc[i]['before']), \n",
    "                                        str(train.loc[i]['after']), \n",
    "                                        train.loc[i]['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = TNCRLDatasetReader(lazy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = reader.read('data/ru_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = next(it.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "index() missing 1 required positional argument: 'vocab'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-27-3bb6b2ce1ab0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0minst\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfields\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'tokens_before'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: index() missing 1 required positional argument: 'vocab'"
     ]
    }
   ],
   "source": [
    "inst.fields['tokens_before'].index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}